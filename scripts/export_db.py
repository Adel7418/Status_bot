"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö SQLite –≤ JSON
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python export_db.py [--output <filename>]
"""

import argparse
import json
import sqlite3
from datetime import datetime
from pathlib import Path


def export_database(db_path: str = "bot_database.db", output_path: str = None) -> str:
    """
    –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ SQLite –≤ JSON

    Args:
        db_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    """

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –ë–î
    if not Path(db_path).exists():
        raise FileNotFoundError(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {db_path}")

    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    export_data = {
        "export_date": datetime.now().isoformat(),
        "database_path": db_path,
        "tables": {},
        "metadata": {},
    }

    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ç–∞–±–ª–∏—Ü
    cursor.execute(
        "SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';"
    )
    tables = [row[0] for row in cursor.fetchall()]

    print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(tables)}")

    # –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∫–∞–∂–¥–æ–π —Ç–∞–±–ª–∏—Ü—ã
    total_rows = 0
    for table in tables:
        print(f"  üìã –≠–∫—Å–ø–æ—Ä—Ç —Ç–∞–±–ª–∏—Ü—ã: {table}...", end=" ")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ö–µ–º—ã —Ç–∞–±–ª–∏—Ü—ã
        cursor.execute(f"PRAGMA table_info({table})")
        schema = cursor.fetchall()
        export_data["metadata"][table] = {
            "columns": [
                {"name": col[1], "type": col[2], "notnull": bool(col[3]), "pk": bool(col[5])}
                for col in schema
            ]
        }

        # –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
        cursor.execute(f"SELECT * FROM {table}")
        rows = cursor.fetchall()
        export_data["tables"][table] = [dict(row) for row in rows]

        total_rows += len(rows)
        print(f"‚úÖ ({len(rows)} —Å—Ç—Ä–æ–∫)")

    conn.close()

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    if output_path is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = f"db_export_{timestamp}.json"

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∞–∑–º–µ—Ä–µ
    file_size = Path(output_path).stat().st_size / 1024  # KB
    db_size = Path(db_path).stat().st_size / 1024  # KB

    print()
    print("‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
    print(f"  üìÅ –§–∞–π–ª: {output_path}")
    print(f"  üìä –¢–∞–±–ª–∏—Ü: {len(tables)}")
    print(f"  üìù –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {total_rows}")
    print(f"  üíæ –†–∞–∑–º–µ—Ä –ë–î: {db_size:.2f} KB")
    print(f"  üíæ –†–∞–∑–º–µ—Ä JSON: {file_size:.2f} KB")

    return output_path


def main():
    parser = argparse.ArgumentParser(description="–≠–∫—Å–ø–æ—Ä—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö SQLite –≤ JSON")

    parser.add_argument(
        "--database",
        "-d",
        type=str,
        default="bot_database.db",
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: bot_database.db)",
    )

    parser.add_argument(
        "--output",
        "-o",
        type=str,
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: db_export_<timestamp>.json)",
    )

    args = parser.parse_args()

    try:
        export_database(args.database, args.output)
    except FileNotFoundError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return 1
    except Exception as e:
        print(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
