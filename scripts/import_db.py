"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON –≤ SQLite
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python import_db.py <json_file> [--database <db_file>]
"""

import argparse
import json
import sqlite3
from datetime import datetime
from pathlib import Path


def import_database(json_path: str, db_path: str = "bot_database.db", clear_existing: bool = False) -> None:
    """
    –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON –≤ SQLite

    Args:
        json_path: –ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å —ç–∫—Å–ø–æ—Ä—Ç–æ–º
        db_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        clear_existing: –û—á–∏—Å—Ç–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º
    """

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è JSON —Ñ–∞–π–ª–∞
    if not Path(json_path).exists():
        raise FileNotFoundError(f"JSON —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {json_path}")

    # –ß—Ç–µ–Ω–∏–µ JSON
    print(f"üìñ –ß—Ç–µ–Ω–∏–µ JSON —Ñ–∞–π–ª–∞: {json_path}")
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    print(f"  üìÖ –î–∞—Ç–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {data.get('export_date', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
    print(f"  üìä –¢–∞–±–ª–∏—Ü –≤ —ç–∫—Å–ø–æ—Ä—Ç–µ: {len(data['tables'])}")

    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';")
    existing_tables = set(row[0] for row in cursor.fetchall())

    # –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
    total_rows = 0
    skipped_tables = []

    for table_name, rows in data["tables"].items():
        if not rows:
            print(f"  ‚è≠Ô∏è  –¢–∞–±–ª–∏—Ü–∞ {table_name}: –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö)")
            skipped_tables.append(table_name)
            continue

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
        if table_name not in existing_tables:
            print(f"  ‚ö†Ô∏è  –¢–∞–±–ª–∏—Ü–∞ {table_name}: –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –ë–î (–ø—Ä–æ–ø—É—â–µ–Ω–∞)")
            skipped_tables.append(table_name)
            continue

        print(f"  üìã –ò–º–ø–æ—Ä—Ç —Ç–∞–±–ª–∏—Ü—ã: {table_name}...", end=" ")

        # –û—á–∏—Å—Ç–∫–∞ —Ç–∞–±–ª–∏—Ü—ã –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        if clear_existing:
            cursor.execute(f"DELETE FROM {table_name}")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        columns = list(rows[0].keys())
        placeholders = ",".join(["?" for _ in columns])
        columns_str = ",".join(columns)

        # –í—Å—Ç–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        inserted = 0
        errors = 0

        for row in rows:
            values = [row.get(col) for col in columns]
            try:
                cursor.execute(f"INSERT OR REPLACE INTO {table_name} ({columns_str}) VALUES ({placeholders})", values)
                inserted += 1
            except sqlite3.Error as e:
                errors += 1
                if errors <= 3:  # –ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3 –æ—à–∏–±–∫–∏
                    print(f"\n    ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ: {e}")

        total_rows += inserted
        print(f"‚úÖ ({inserted} —Å—Ç—Ä–æ–∫, –æ—à–∏–±–æ–∫: {errors})")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    conn.commit()
    conn.close()

    # –ò—Ç–æ–≥–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    print()
    print("‚úÖ –ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
    print(f"  üìÅ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {db_path}")
    print(f"  üìä –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(data['tables']) - len(skipped_tables)}")
    print(f"  üìù –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {total_rows}")
    if skipped_tables:
        print(f"  ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(skipped_tables)} ({', '.join(skipped_tables)})")

    # –†–∞–∑–º–µ—Ä –ë–î
    db_size = Path(db_path).stat().st_size / 1024  # KB
    print(f"  üíæ –†–∞–∑–º–µ—Ä –ë–î: {db_size:.2f} KB")


def main():
    parser = argparse.ArgumentParser(description="–ò–º–ø–æ—Ä—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON –≤ SQLite")

    parser.add_argument("json_file", type=str, help="–ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å —ç–∫—Å–ø–æ—Ä—Ç–æ–º")

    parser.add_argument(
        "--database", "-d", type=str, default="bot_database.db", help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: bot_database.db)"
    )

    parser.add_argument(
        "--clear",
        "-c",
        action="store_true",
        help="–û—á–∏—Å—Ç–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º",
    )

    parser.add_argument(
        "--backup",
        "-b",
        action="store_true",
        help="–°–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –ë–î –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º",
    )

    args = parser.parse_args()

    # –°–æ–∑–¥–∞–Ω–∏–µ backup –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
    if args.backup and Path(args.database).exists():
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = f"{args.database}.backup_{timestamp}"
        import shutil

        shutil.copy2(args.database, backup_path)
        print(f"üíæ –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_path}")
        print()

    try:
        import_database(args.json_file, args.database, args.clear)
    except FileNotFoundError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return 1
    except json.JSONDecodeError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è JSON: {e}")
        return 1
    except Exception as e:
        print(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback

        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    exit(main())

