# –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: Telegram Repair Bot

**–î–∞—Ç–∞:** 19 –æ–∫—Ç—è–±—Ä—è 2025
**–í–µ—Ä—Å–∏—è –ø—Ä–æ–µ–∫—Ç–∞:** 1.1.0
**–°—Ç–∞—Ç—É—Å:** Critical Review - Production Readiness Assessment

---

## üîë –ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ –∏—Ö –≤–µ—Ä—Å–∏–∏

### –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–µ–∫ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)

| –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ | –í–µ—Ä—Å–∏—è | Trust Score | Snippets | –°—Ç–∞—Ç—É—Å |
|-----------|--------|-------------|----------|--------|
| **aiogram** | 3.16.0 | 7.5/10 | 4423 | ‚úÖ –ê–∫—Ç—É–∞–ª—å–Ω–∞—è |
| **pydantic** | 2.10.3 | 9.6/10 | 530 | ‚úÖ –ê–∫—Ç—É–∞–ª—å–Ω–∞—è (v2) |
| **alembic** | 1.13.1 | - | 363 | ‚úÖ –ê–∫—Ç—É–∞–ª—å–Ω–∞—è |
| **aiosqlite** | 0.20.0 | - | - | ‚úÖ –ê–∫—Ç—É–∞–ª—å–Ω–∞—è |
| **APScheduler** | 3.11.0 | - | - | ‚ö†Ô∏è Stable (v4 breaking) |
| **openpyxl** | 3.1.5 | - | - | ‚úÖ –ê–∫—Ç—É–∞–ª—å–Ω–∞—è |

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è

| –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ | –í–µ—Ä—Å–∏—è | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç |
|-----------|--------|------------|----------|
| **Redis** | 5.2.1+ | FSM Storage (–ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å) | P0 |
| **PostgreSQL** | 14+ | Production –ë–î | P0 |
| **asyncpg** | 0.29.0 | Async PostgreSQL driver | P0 |
| **SQLAlchemy** | 2.0+ | ORM (–≤–º–µ—Å—Ç–æ raw SQL) | P1 |
| **Sentry** | 2.19.0+ | Error tracking | P1 |
| **Prometheus** | - | –ú–µ—Ç—Ä–∏–∫–∏ | P1 |
| **pytest** | 8.3.0+ | –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤ | P1 |

---

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫ (Context7)

### Aiogram 3.x

**Library ID:** `/websites/aiogram_dev_en_v3_22_0`
**Trust Score:** 7.5/10
**Code Snippets:** 4423

**–ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
- ‚úÖ Async/await –Ω–∞—Ç–∏–≤–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞
- ‚úÖ FSM (Finite State Machine) –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤
- ‚úÖ Middleware chain
- ‚úÖ Webhook –∏ Long polling
- ‚úÖ Type hints –∏ Pydantic integration

**–ö—Ä–∏—Ç–∏—á–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞:**
1. **Rate limiting:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `aiogram.utils.token_bucket.TokenBucket`
   ```python
   from aiogram.utils.token_bucket import TokenBucket

   rate_limiter = TokenBucket(rate=3, capacity=10)  # 3 req/sec, burst 10
   ```

2. **Redis Storage:** –ü–µ—Ä–µ—Ö–æ–¥ —Å MemoryStorage
   ```python
   from aiogram.fsm.storage.redis import RedisStorage

   storage = RedisStorage.from_url("redis://localhost:6379")
   dp = Dispatcher(storage=storage)
   ```

3. **Webhook mode:** –î–ª—è production (–≤–º–µ—Å—Ç–æ long polling)
   ```python
   # bot.py
   await bot.set_webhook(
       url=f"{WEBHOOK_URL}/webhook",
       allowed_updates=["message", "callback_query"]
   )
   ```

**–°—Å—ã–ª–∫–∏:**
- –û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: https://docs.aiogram.dev/en/v3.22.0/
- –ú–∏–≥—Ä–∞—Ü–∏—è v2‚Üív3: https://docs.aiogram.dev/en/v3.22.0/migration_2_to_3.html
- Best practices: https://mastergroosha.github.io/aiogram-3-guide/ (Trust: 9.4/10)

---

### Pydantic 2.x

**Library ID:** `/pydantic/pydantic`
**Trust Score:** 9.6/10
**Code Snippets:** 530

**–ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
- ‚úÖ Type-safe –≤–∞–ª–∏–¥–∞—Ü–∏—è
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è/–¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è
- ‚úÖ Custom validators
- ‚úÖ Field constraints
- ‚úÖ Performance (Pydantic Core –≤ Rust)

**–¢–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ:**
- ‚úÖ `app/schemas/order.py` - OrderCreateSchema
- ‚úÖ `app/schemas/master.py` - MasterApplicationSchema
- ‚úÖ `app/schemas/user.py` - UserSchema

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
1. **–†–∞—Å—à–∏—Ä–∏—Ç—å —Å—Ö–µ–º—ã –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π:**
   ```python
   # app/schemas/order.py
   from pydantic import BaseModel, Field, field_validator

   class OrderUpdateSchema(BaseModel):
       equipment_type: str | None = None
       description: str | None = Field(None, max_length=500)
       client_name: str | None = None

       @field_validator('client_phone')
       @classmethod
       def validate_phone(cls, v):
           if not re.match(r'^\+?[0-9]{10,15}$', v):
               raise ValueError('Invalid phone format')
           return v
   ```

2. **Callback data –≤–∞–ª–∏–¥–∞—Ü–∏—è:**
   ```python
   from pydantic import BaseModel

   class AssignMasterCallback(BaseModel):
       action: str = "assign_master"
       order_id: int
       master_id: int

   # Usage
   data = AssignMasterCallback(order_id=123, master_id=456)
   await callback.answer(callback_data=data.model_dump_json())
   ```

3. **Config –≤–∞–ª–∏–¥–∞—Ü–∏—è:**
   ```python
   # app/core/config.py
   from pydantic_settings import BaseSettings

   class Settings(BaseSettings):
       bot_token: str = Field(..., min_length=46)
       admin_ids: list[int]
       database_url: str

       model_config = {
           "env_file": ".env",
           "case_sensitive": False
       }

   settings = Settings()
   ```

**–°—Å—ã–ª–∫–∏:**
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: https://docs.pydantic.dev/
- Migration v1‚Üív2: https://docs.pydantic.dev/latest/migration/

---

### Alembic (SQLAlchemy)

**Library ID:** `/sqlalchemy/alembic`
**Code Snippets:** 363

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:**
- ‚úÖ 5 –º–∏–≥—Ä–∞—Ü–∏–π —Å–æ–∑–¥–∞–Ω–æ
- ‚úÖ `alembic.ini` –Ω–∞—Å—Ç—Ä–æ–µ–Ω
- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ö–µ–º—ã

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**

1. **–ê–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∏–≥—Ä–∞—Ü–∏–π:**
   ```bash
   # –í–º–µ—Å—Ç–æ —Ä—É—á–Ω–æ–≥–æ –Ω–∞–ø–∏—Å–∞–Ω–∏—è
   alembic revision --autogenerate -m "Add new field"
   ```

2. **Offline mode –¥–ª—è production:**
   ```python
   # migrations/env.py
   def run_migrations_offline():
       context.configure(
           url=url,
           target_metadata=target_metadata,
           literal_binds=True,
           dialect_opts={"paramstyle": "named"},
       )
   ```

3. **Downgrade —Å—Ç—Ä–∞—Ç–µ–≥–∏—è:**
   ```bash
   # –í—Å–µ–≥–¥–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å rollback
   alembic downgrade -1
   alembic upgrade head
   ```

4. **–ú–∏–≥—Ä–∞—Ü–∏—è –Ω–∞ PostgreSQL:**
   ```ini
   # alembic.ini
   sqlalchemy.url = postgresql+asyncpg://user:pass@localhost/repairbot
   ```

**–°—Å—ã–ª–∫–∏:**
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: https://alembic.sqlalchemy.org/
- Best practices: https://alembic.sqlalchemy.org/en/latest/cookbook.html

---

## üîß –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∏

### 1. –ú–∏–≥—Ä–∞—Ü–∏—è –Ω–∞ SQLAlchemy ORM (P1)

**–ü—Ä–æ–±–ª–µ–º–∞:** Raw SQL –≤ `app/database/db.py` - —Ä–∏—Å–∫ SQL injection, —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫–∏

**–†–µ—à–µ–Ω–∏–µ:**
```python
# app/database/models_orm.py
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column
from sqlalchemy import String, Integer, ForeignKey

class Base(DeclarativeBase):
    pass

class User(Base):
    __tablename__ = "users"

    id: Mapped[int] = mapped_column(primary_key=True)
    telegram_id: Mapped[int] = mapped_column(unique=True)
    username: Mapped[str | None] = mapped_column(String(255))
    role: Mapped[str] = mapped_column(String(100), default="UNKNOWN")

    # Relationships
    orders: Mapped[list["Order"]] = relationship(back_populates="dispatcher")

# app/database/repository.py
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

class UserRepository:
    def __init__(self, session: AsyncSession):
        self.session = session

    async def get_by_telegram_id(self, telegram_id: int) -> User | None:
        result = await self.session.execute(
            select(User).where(User.telegram_id == telegram_id)
        )
        return result.scalar_one_or_none()

    async def create(self, user_data: dict) -> User:
        user = User(**user_data)
        self.session.add(user)
        await self.session.commit()
        return user
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ Type safety
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç SQL injection
- ‚úÖ Relationships (lazy loading, eager loading)
- ‚úÖ Query composition

---

### 2. Repository Pattern (P2)

**–ü—Ä–æ–±–ª–µ–º–∞:** Handlers –Ω–∞–ø—Ä—è–º—É—é —Ä–∞–±–æ—Ç–∞—é—Ç —Å Database

**–†–µ—à–µ–Ω–∏–µ:**
```python
# app/repositories/order_repository.py
class OrderRepository:
    def __init__(self, db: Database):
        self.db = db

    async def create(self, data: OrderCreateSchema) -> Order:
        # –ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞ + –≤–∞–ª–∏–¥–∞—Ü–∏—è
        return await self.db.create_order(**data.model_dump())

    async def get_by_id(self, order_id: int) -> Order | None:
        return await self.db.get_order_by_id(order_id)

    async def assign_master(self, order_id: int, master_id: int) -> bool:
        # –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞
        async with self.db.transaction():
            order = await self.get_by_id(order_id)
            if not order:
                raise OrderNotFound(order_id)

            # Validate state transition
            if order.status not in [OrderStatus.NEW, OrderStatus.REFUSED]:
                raise InvalidStateTransition(order.status, OrderStatus.ASSIGNED)

            return await self.db.assign_master_to_order(order_id, master_id)

# app/handlers/dispatcher.py
@router.callback_query(F.data.startswith("assign_master_"))
async def assign_master_handler(
    callback: CallbackQuery,
    order_repo: OrderRepository = Depends()  # DI
):
    _, _, order_id, master_id = callback.data.split("_")
    try:
        await order_repo.assign_master(int(order_id), int(master_id))
        await callback.answer("‚úÖ –ú–∞—Å—Ç–µ—Ä –Ω–∞–∑–Ω–∞—á–µ–Ω")
    except OrderNotFound:
        await callback.answer("‚ùå –ó–∞—è–≤–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", show_alert=True)
    except InvalidStateTransition as e:
        await callback.answer(f"‚ùå {e}", show_alert=True)
```

---

### 3. State Machine –¥–ª—è Order (P0)

**–ü—Ä–æ–±–ª–µ–º–∞:** –ù–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ —Å—Ç–∞—Ç—É—Å–æ–≤

**–†–µ—à–µ–Ω–∏–µ:**
```python
# app/domain/order_state_machine.py
from enum import Enum
from typing import Set

class OrderStatus(str, Enum):
    NEW = "NEW"
    ASSIGNED = "ASSIGNED"
    ACCEPTED = "ACCEPTED"
    ONSITE = "ONSITE"
    CLOSED = "CLOSED"
    REFUSED = "REFUSED"
    DR = "DR"

class OrderStateMachine:
    TRANSITIONS: dict[OrderStatus, Set[OrderStatus]] = {
        OrderStatus.NEW: {OrderStatus.ASSIGNED, OrderStatus.REFUSED},
        OrderStatus.ASSIGNED: {OrderStatus.ACCEPTED, OrderStatus.REFUSED},
        OrderStatus.ACCEPTED: {OrderStatus.ONSITE, OrderStatus.DR},
        OrderStatus.ONSITE: {OrderStatus.CLOSED, OrderStatus.DR},
        OrderStatus.DR: {OrderStatus.CLOSED},
        OrderStatus.REFUSED: {OrderStatus.NEW},  # Reopen
        OrderStatus.CLOSED: set(),  # Terminal state
    }

    @classmethod
    def can_transition(cls, from_state: OrderStatus, to_state: OrderStatus) -> bool:
        return to_state in cls.TRANSITIONS.get(from_state, set())

    @classmethod
    def validate_transition(cls, from_state: OrderStatus, to_state: OrderStatus):
        if not cls.can_transition(from_state, to_state):
            raise InvalidStateTransition(
                f"Cannot transition from {from_state} to {to_state}"
            )

# Usage in repository
async def update_status(self, order_id: int, new_status: OrderStatus):
    order = await self.get_by_id(order_id)
    OrderStateMachine.validate_transition(order.status, new_status)
    await self.db.update_order_status(order_id, new_status)
```

---

### 4. Dependency Injection (P2)

**–ü—Ä–æ–±–ª–µ–º–∞:** –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

**–†–µ—à–µ–Ω–∏–µ:**
```python
# app/di.py (Dependency Injector)
from aiogram import Dispatcher
from collections.abc import AsyncGenerator

async def get_db() -> AsyncGenerator[Database, None]:
    db = Database()
    await db.connect()
    try:
        yield db
    finally:
        await db.disconnect()

async def get_order_repo(db: Database = Depends(get_db)) -> OrderRepository:
    return OrderRepository(db)

# Register in dispatcher
def setup_di(dp: Dispatcher):
    dp["db"] = Database()
    dp["order_repo"] = OrderRepository(dp["db"])

# Usage in handlers
@router.message(Command("create_order"))
async def create_order_cmd(
    message: Message,
    state: FSMContext,
    order_repo: OrderRepository = Depends(get_order_repo)
):
    # Handler logic
    pass
```

---

## üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### 1. –°–µ–∫—Ä–µ—Ç—ã (P0)

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:** `.env` —Ñ–∞–π–ª —Å plaintext —Ç–æ–∫–µ–Ω–∞–º–∏

**–†–µ—à–µ–Ω–∏–µ:**

**Docker Secrets:**
```yaml
# docker-compose.yml
version: '3.8'
services:
  bot:
    secrets:
      - bot_token
      - database_url
    environment:
      BOT_TOKEN_FILE: /run/secrets/bot_token
      DATABASE_URL_FILE: /run/secrets/database_url

secrets:
  bot_token:
    external: true
  database_url:
    external: true
```

```python
# app/core/config.py
import os

def read_secret(name: str) -> str:
    secret_file = os.getenv(f"{name}_FILE")
    if secret_file and os.path.exists(secret_file):
        with open(secret_file) as f:
            return f.read().strip()
    return os.getenv(name, "")

class Config:
    BOT_TOKEN = read_secret("BOT_TOKEN")
    DATABASE_URL = read_secret("DATABASE_URL")
```

**HashiCorp Vault (–¥–ª—è enterprise):**
```python
import hvac

client = hvac.Client(url='https://vault:8200')
client.token = os.getenv('VAULT_TOKEN')

secrets = client.secrets.kv.v2.read_secret_version(path='repairbot')
BOT_TOKEN = secrets['data']['data']['bot_token']
```

---

### 2. Rate Limiting (P0)

**–†–µ—à–µ–Ω–∏–µ:**
```python
# app/middlewares/rate_limit.py
from aiogram import BaseMiddleware
from aiogram.types import Message, CallbackQuery
from cachetools import TTLCache

class RateLimitMiddleware(BaseMiddleware):
    def __init__(self, rate: int = 3, period: int = 1):
        self.cache = TTLCache(maxsize=10000, ttl=period)
        self.rate = rate

    async def __call__(self, handler, event, data):
        user_id = event.from_user.id

        # Check rate
        requests = self.cache.get(user_id, 0)
        if requests >= self.rate:
            if isinstance(event, Message):
                await event.answer("‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–¥–æ–∂–¥–∏—Ç–µ.")
            else:
                await event.answer("‚ö†Ô∏è Rate limit", show_alert=True)
            return

        # Increment counter
        self.cache[user_id] = requests + 1

        return await handler(event, data)

# Register
dp.message.middleware(RateLimitMiddleware(rate=3, period=1))
```

---

### 3. PII Masking (P1)

**–†–µ—à–µ–Ω–∏–µ:**
```python
# app/utils/logging.py
import re
import logging

class PIIMaskingFilter(logging.Filter):
    PATTERNS = {
        'phone': (r'\+?\d{10,15}', lambda m: m.group()[:3] + '*' * 7),
        'address': (r'—É–ª\.\s+[\w\s,]+\d+', lambda m: '***–∞–¥—Ä–µ—Å***'),
        'name': (r'[–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å][–∞-—è—ë]+', lambda m: '***–§–ò–û***'),
    }

    def filter(self, record):
        message = record.getMessage()
        for pattern, replacer in self.PATTERNS.values():
            message = re.sub(pattern, replacer, message)
        record.msg = message
        return True

# Setup
logger = logging.getLogger(__name__)
logger.addFilter(PIIMaskingFilter())
```

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ observability

### 1. Sentry Integration (P1)

```python
# app/utils/sentry.py
import sentry_sdk
from sentry_sdk.integrations.asyncio import AsyncioIntegration
from sentry_sdk.integrations.logging import LoggingIntegration

def init_sentry():
    if not Config.SENTRY_DSN:
        return

    sentry_sdk.init(
        dsn=Config.SENTRY_DSN,
        environment=Config.ENVIRONMENT,
        traces_sample_rate=0.1,  # 10% transactions
        profiles_sample_rate=0.1,
        integrations=[
            AsyncioIntegration(),
            LoggingIntegration(level=logging.INFO, event_level=logging.ERROR)
        ],
        before_send=before_send_filter,
    )

def before_send_filter(event, hint):
    # –ú–∞—Å–∫–∏—Ä—É–µ–º PII –≤ Sentry
    if 'request' in event:
        if 'data' in event['request']:
            # Mask sensitive fields
            pass
    return event
```

---

### 2. Prometheus Metrics (P1)

```python
# app/utils/metrics.py
from prometheus_client import Counter, Histogram, Gauge
from prometheus_client import start_http_server

# Metrics
orders_created = Counter('orders_created_total', 'Total orders created')
orders_by_status = Gauge('orders_by_status', 'Orders by status', ['status'])
handler_duration = Histogram('handler_duration_seconds', 'Handler duration', ['handler'])

# Export
start_http_server(8000)  # Prometheus scrape endpoint

# Usage in handlers
@handler_duration.labels(handler='create_order').time()
async def create_order_handler(message: Message):
    # ...
    orders_created.inc()
    orders_by_status.labels(status='NEW').inc()
```

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ coverage (P1)

**–¶–µ–ª—å:** 80% coverage

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è:**

1. **Unit —Ç–µ—Å—Ç—ã (handlers):**
```python
# tests/unit/test_order_handlers.py
import pytest
from aiogram.test_utils.mocked_bot import MockedBot
from app.handlers.dispatcher import create_order_handler

@pytest.mark.asyncio
async def test_create_order_success(mock_db, mock_order_repo):
    bot = MockedBot()
    message = bot.get_message(text="/create_order", from_user=bot.user)

    await create_order_handler(message, state=FSMContext())

    assert message.answer.called
    assert "–≤—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø —Ç–µ—Ö–Ω–∏–∫–∏" in message.answer.call_args[0][0].lower()
```

2. **Integration —Ç–µ—Å—Ç—ã (database):**
```python
# tests/integration/test_order_flow.py
@pytest.mark.asyncio
async def test_full_order_lifecycle(db):
    # Create order
    order = await db.create_order(
        equipment_type="–°—Ç–∏—Ä–∞–ª—å–Ω–∞—è –º–∞—à–∏–Ω–∞",
        description="–ù–µ –≤–∫–ª—é—á–∞–µ—Ç—Å—è",
        client_name="–ò–≤–∞–Ω",
        client_address="—É–ª. –õ–µ–Ω–∏–Ω–∞ 1",
        client_phone="+79991234567",
        dispatcher_id=123456789
    )
    assert order.status == OrderStatus.NEW

    # Assign master
    await db.assign_master_to_order(order.id, master_id=1)
    order = await db.get_order_by_id(order.id)
    assert order.status == OrderStatus.ASSIGNED

    # Close order
    await db.update_order_status(order.id, OrderStatus.CLOSED)
    order = await db.get_order_by_id(order.id)
    assert order.status == OrderStatus.CLOSED
```

3. **E2E —Ç–µ—Å—Ç—ã (bot interaction):**
```python
# tests/e2e/test_bot_commands.py
@pytest.mark.asyncio
async def test_start_command_flow():
    async with BotTestClient() as client:
        # Send /start
        response = await client.send("/start")
        assert "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å" in response.text

        # Click "–°–æ–∑–¥–∞—Ç—å –∑–∞—è–≤–∫—É"
        response = await client.click_button("–°–æ–∑–¥–∞—Ç—å –∑–∞—è–≤–∫—É")
        assert "–≤—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø —Ç–µ—Ö–Ω–∏–∫–∏" in response.text
```

---

## üìà Performance

### 1. –ü–∞–≥–∏–Ω–∞—Ü–∏—è (P2)

**–ü—Ä–æ–±–ª–µ–º–∞:** `get_all_orders()` –±–µ–∑ –ª–∏–º–∏—Ç–æ–≤ ‚Üí OOM

**–†–µ—à–µ–Ω–∏–µ:**
```python
# app/repositories/order_repository.py
async def get_paginated(
    self,
    page: int = 1,
    page_size: int = 20,
    filters: dict | None = None
) -> tuple[list[Order], int]:
    offset = (page - 1) * page_size

    query = select(Order)
    if filters:
        # Apply filters
        pass

    # Get total count
    count_query = select(func.count()).select_from(Order)
    total = await self.session.scalar(count_query)

    # Get page
    query = query.offset(offset).limit(page_size)
    result = await self.session.execute(query)
    orders = result.scalars().all()

    return orders, total

# Inline keyboard pagination
def build_order_list_keyboard(page: int, total_pages: int):
    keyboard = InlineKeyboardBuilder()

    # Orders on current page
    for order in orders:
        keyboard.button(text=f"#{order.id}", callback_data=f"order_{order.id}")

    # Pagination buttons
    row = []
    if page > 1:
        row.append(InlineKeyboardButton(text="‚óÄÔ∏è", callback_data=f"orders_page_{page-1}"))
    row.append(InlineKeyboardButton(text=f"{page}/{total_pages}", callback_data="noop"))
    if page < total_pages:
        row.append(InlineKeyboardButton(text="‚ñ∂Ô∏è", callback_data=f"orders_page_{page+1}"))

    keyboard.row(*row)
    return keyboard.as_markup()
```

---

### 2. Connection pooling (PostgreSQL)

```python
# app/database/engine.py
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

engine = create_async_engine(
    Config.DATABASE_URL,
    pool_size=20,  # Max connections
    max_overflow=10,  # Extra connections
    pool_pre_ping=True,  # Verify connections
    echo=False,
)

AsyncSessionLocal = sessionmaker(
    engine, class_=AsyncSession, expire_on_commit=False
)
```

---

## üöÄ Deployment

### Production checklist

```bash
# Environment
export ENVIRONMENT=production
export DEV_MODE=false
export LOG_LEVEL=INFO

# Database
export DATABASE_URL=postgresql+asyncpg://user:pass@postgres:5432/repairbot

# Redis
export REDIS_URL=redis://redis:6379/0

# Monitoring
export SENTRY_DSN=https://xxx@sentry.io/xxx

# Start
docker-compose -f docker-compose.prod.yml up -d
```

**docker-compose.prod.yml:**
```yaml
version: '3.8'

services:
  bot:
    image: ghcr.io/your-org/telegram-repair-bot:latest
    restart: always
    env_file:
      - .env.production
    depends_on:
      - postgres
      - redis
    healthcheck:
      test: ["CMD", "python", "-c", "import asyncio; asyncio.run(...)"]
      interval: 30s
      timeout: 10s
      retries: 3

  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: repairbot
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus

  grafana:
    image: grafana/grafana:latest
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:
```

---

## üìù –ò—Ç–æ–≥–æ–≤—ã–π action plan

### Week 1-2: Critical fixes (P0)
- [ ] Docker secrets –¥–ª—è BOT_TOKEN
- [ ] Redis FSM storage
- [ ] Rate limiting middleware
- [ ] State machine –¥–ª—è Order
- [ ] PostgreSQL setup

### Week 3-4: High priority (P1)
- [ ] SQLAlchemy ORM migration
- [ ] Sentry integration
- [ ] Transaction isolation
- [ ] PII masking
- [ ] Idempotency keys

### Week 5-6: Quality improvements (P2)
- [ ] Test coverage 80%+
- [ ] Repository pattern
- [ ] Pagination
- [ ] CI/CD pipeline
- [ ] Prometheus metrics

---

**–î–æ–∫—É–º–µ–Ω—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Context7 –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫**
**–í–µ—Ä—Å–∏—è:** 1.0
**–î–∞—Ç–∞:** 19 –æ–∫—Ç—è–±—Ä—è 2025
